{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UTS Pembelajaran Mesin (Ilmu Komputer Kelas A, B dan IUP) 2019/2020\n",
    "## Tanggal Pengumpulan: 9 April 2020 jam 6.00\n",
    "## Nama/NIM: Waffiq Maaroja / 17/409448/PA/17755\n",
    "## Kelas: A\n",
    "## Total Score: 40\n",
    "## Submit pada assignment kelas masing-masing dengan nama file UTS_Nama\n",
    "\n",
    "### Petunjuk soal\n",
    "Lengkapi kode implementasi Neural Network di bawah ini. <br>\n",
    "Perhatikan score untuk tiap bagian kode <br>\n",
    "Sertakan penjelasan singkat (dalam bentuk markdown) untuk tiap function yang ditulis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fungsi ini digunakan untuk membaca dataset yang berupa csv file\n",
    "# expected_output: data dalam bentuk list\n",
    "# score: 2\n",
    "\n",
    "from csv import reader\n",
    "import numpy as np\n",
    "\n",
    "def load_csv(filename):\n",
    "    dataset = list()\n",
    "    with open(filename, 'r') as file:\n",
    "        csv_reader = reader(file)\n",
    "        for row in csv_reader:\n",
    "            if not row:\n",
    "                continue\n",
    "            dataset.append(row)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perhatikan data csv, data yang diberikan masih dalam bentuk string\n",
    "# Buat fungsi untuk meng-convert feature (X) ke dalam float, dan target (Y) ke dalam integer\n",
    "# note: pada dataset yang diberikan, target ada pada kolom terakhir\n",
    "# note: kode boleh dibuat dalam 2 fungsi (seperti contoh di bawah)  atau 1 fungsi saja.\n",
    "# expected_output: matrix X (feature)  dan vector Y (target), \n",
    "# score: 4\n",
    "\n",
    "def str_feature_to_float(dataset):\n",
    "    X = list()\n",
    "    for row in dataset:\n",
    "        x_row = [float(x) for x in row[:-1]]\n",
    "        X.append(x_row)\n",
    "    X = np.array(X)\n",
    "    return X\n",
    "\n",
    "def str_target_to_integer(dataset):\n",
    "    Y = list()\n",
    "    for row in dataset:\n",
    "        y_row = int(row[-1])\n",
    "        Y.append(y_row)\n",
    "    Y = np.array(Y)\n",
    "    return Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data ke train dan test (baik untuk X maupun Y), dengan komposisi training size:80%, test size: 20%\n",
    "# boleh menggunakan fungsi dari scikit learn\n",
    "# expected_output: X_train, X_test, Y_train, Y_test \n",
    "# score: 2\n",
    "\n",
    "from sklearn.model_selection import train_test_split as splitter\n",
    "\n",
    "def train_test_split (X, Y):\n",
    "    X_train, X_test, Y_train, Y_test = splitter(X, Y, test_size = 0.2)\n",
    "    return X_train, X_test, Y_train, Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ubah target (Y_train dan Y_test) ke dalam bentuk representasi one_hot_encoding\n",
    "# hint: gunakan np.eye dari Numpy\n",
    "# expected_output: target dalam bentuk one_hot_encoded\n",
    "# score: 2\n",
    "\n",
    "def one_hot_encoding (target):\n",
    "    maks_y = np.max(target) + 1\n",
    "    encoded = np.eye(maks_y)[target]\n",
    "    target_encoded = np.delete(encoded, obj=0, axis=1)\n",
    "    print(target)\n",
    "    print(target_encoded)\n",
    "    return target_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Asumsikan bahwa ada 3 layer pada Neural Network yaitu input layer, hidden layer dan output layer\n",
    "# set n_inputs dengan banyaknya fitur, n_hidden dengan 20 dan n_outputs dengan jumlah kelas\n",
    "# inisialisasi network parameter (Theta_1: parameter dari input ke hidden) \n",
    "# dan (Theta_2: parameter dari hidden ke output) dengan random number\n",
    "# hint: Perhatikan dimensi dari Theta_1 dan Theta_2, jangan lupa ada parameter bias.\n",
    "# expected_output: Theta_1 dan Theta_2 yang sudah diinisialisasi\n",
    "# score: 2\n",
    "\n",
    "from random import seed\n",
    "from random import random\n",
    "seed(1)\n",
    " \n",
    "def initialize_network(n_inputs, n_hidden, n_outputs):\n",
    "    Theta_1 = np.random.random_sample((n_hidden, n_inputs + 1))\n",
    "    Theta_2 = np.random.random_sample((n_outputs, n_hidden + 1))\n",
    "    return [Theta_1, Theta_2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tuliskan fungsi sigmoid\n",
    "# fungsi ini harus bisa menerima input baik berupa matrix, vector maupun scalar \n",
    "# expected_output: sigmoid value (untuk setiap elemen pada matrix/vector) \n",
    "# score: 2\n",
    "\n",
    "def sigmoid_function(z):\n",
    "    z = np.array(z)\n",
    "    sigmoid_value = 1 / (1 + np.exp(-z))\n",
    "    return sigmoid_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tuliskan fungsi untuk regularized cost function dari Neural Network (J) \n",
    "# Set lambda (regularisation parameter ke 0.8)\n",
    "# expected_output: cost value\n",
    "# score: 2\n",
    "\n",
    "def cost_function(theta, Y_actual, Y_predicted, Lambda):\n",
    "    m = Y_actual.shape[0]\n",
    "    left = np.multiply(np.log(Y_predicted), Y_actual)\n",
    "    right = np.multiply(np.log(1 - Y_predicted), 1 - Y_actual)\n",
    "    loss = -np.sum(left + right) / m\n",
    "    regular = 0\n",
    "    for t in theta:\n",
    "        regular += (np.sum(t**2) * Lambda / (2*m))\n",
    "    J = regular + loss\n",
    "    return J"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tuliskan fungsi forward propagation\n",
    "# expected_output: a(2) output dari hidden layer dan a(3) output dari output layer\n",
    "# hint: lihat slide NN part 1 mengenai forward propagation untuk detail cara menghitungnya\n",
    "# note: pada layer 1 (input) dan layer 2 (hidden layer) terdapat bias yang nilainya di set sama dengan 1\n",
    "# score: 4\n",
    "\n",
    "def forward_propagation(theta, x):\n",
    "    bias = [np.ones((1,1), dtype=np.float64) for _ in range(len(theta))]\n",
    "    vector = np.reshape(x, (len(x), 1))\n",
    "    a = []\n",
    "    for i in range(len(bias)):\n",
    "        vector = np.append(bias[i], vector, axis=0)\n",
    "        a.append(vector)\n",
    "        vector = np.matmul(theta[i], vector)\n",
    "        vector = sigmoid_function(vector)\n",
    "    a.append(vector)\n",
    "    return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tuliskan fungsi gradient/derivatif dari sigmoid function\n",
    "# fungsi ini harus bisa menerima input baik berupa matrix, vector maupun scalar \n",
    "# expected_output: gradient sigmoid value (untuk setiap elemen pada matrix/vector)\n",
    "# score: 2\n",
    "\n",
    "def gradient_sigmoid_function(a):\n",
    "    a = np.array(a)\n",
    "    gradient_sigmoid_value = a * (1 - a)\n",
    "    return gradient_sigmoid_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tuliskan fungsi back propagation untuk menghitung eror dan update parameter dengan algoritma gradient descent\n",
    "# expected_output: parameter update\n",
    "# hint: lihat slide NN part 2 mengenai back propagation untuk detail cara menghitungnya\n",
    "# note: parameter bias tidak termasuk yang dikenai regularisasi\n",
    "# note: parameter harus di update secara simultan (ingat lagi dibagian gradient descent)\n",
    "# score: 4\n",
    "\n",
    "def back_propagation(theta, big_delta, a, y):\n",
    "    layer = len(a)\n",
    "    y = np.reshape(y, (len(y), 1))\n",
    "    a = a[::-1]\n",
    "    theta = theta[::-1]\n",
    "    \n",
    "    error = []\n",
    "    delta = a[0] - y\n",
    "    error.append(delta)\n",
    "    for k in range(1, layer-1):\n",
    "        delta = np.matmul(np.transpose(theta[k-1]), error[k-1]) * gradient_sigmoid_function(a[k])\n",
    "        delta = np.delete(delta, obj=0, axis=0)\n",
    "        error.append(delta)\n",
    "    error = error[::-1]\n",
    "    a = a[::-1]\n",
    "    \n",
    "    new_big_delta = []\n",
    "    for k in range(len(error)):\n",
    "        delta = np.matmul(error[k], np.transpose(a[k]))\n",
    "        new_big_delta.append(big_delta[k] + delta)\n",
    "    return new_big_delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parameter_update(theta, big_delta, data_count, Lambda, learning_rate):\n",
    "    new_theta = []\n",
    "    for k in range(len(theta)):\n",
    "        theta_non_bias = np.delete(theta[k], obj=0, axis=1)\n",
    "        zeros = np.zeros((theta[k].shape[0], 1), dtype=np.float64)\n",
    "        teta = np.append(zeros, theta_non_bias, axis=1)\n",
    "        J_derivatif = (Lambda * teta) + (big_delta[k] / data_count)\n",
    "        new_theta.append(theta[k] - (learning_rate * J_derivatif))\n",
    "    return new_theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluasi/testing dengan melakukan prediksi pada data test\n",
    "# hint: untuk melakukan prediksi, gunakan fungsi forward_propagation dengan parameter Theta_1 dan Theta_2 \n",
    "# yang telah diperoleh dari training, jangan lupa target berupa one hot encoded, probability yang dihasilkan \n",
    "# dari layer output dibulatkan (round), jika >= 0.5 ke 1 dan jika < 0.5 ke 0\n",
    "# tuliskan fungsi untuk menghitung akurasi (total prediksi benar dibagi total data)\n",
    "# expected_output: akurasi\n",
    "# score: 4\n",
    "\n",
    "def calculate_accuracy(test_input, test_target):\n",
    "    benar = 0\n",
    "    n = test_input.shape[0]\n",
    "    for k in range(n):\n",
    "        a = forward_propagation(Theta, test_input[k])\n",
    "        a = np.where(a[-1].flatten() >= 0.5, 1, 0)\n",
    "        if np.sum(np.abs(a - test_target[k])) == 0:\n",
    "            benar += 1\n",
    "    accuracy = benar / n\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 3 3 1 1 3 1 3 3 2 3 3 1 1 3 2 2 1 3 1 3 2 3 1 2 3 2 1 2 2 1 3 3 1 2 3 1\n",
      " 3 1 3 2 1 1 2 1 2 3 1 2 3 3 2 3 3 1 3 1 2 3 1 3 2 2 2 1 1 3 3 3 1 3 2 2 2\n",
      " 1 3 2 1 2 3 2 3 2 1 1 2 2 1 3 1 3 3 3 3 2 1 2 2 1 2 2 2 1 2 1 3 3 1 2 3 2\n",
      " 1 2 3 1 2 1 1 2 1 1 2 3 2 1 2 3 1 1 1 3 1 1 1 3 1 2 2 1 1 2 1 3 3 2 3 3 2\n",
      " 2 3 2 1 3 2 2 3 1 1 3 2 2 2 2 3 3 2 2 1]\n",
      "[[0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]]\n",
      "[3 3 2 2 2 1 3 1 1 1 3 3 2 3 3 1 1 3 2 2 1 3 1 1 2 2 2 3 1 1 2 3 1 1 3 3 2\n",
      " 3 1 2 3 1]\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "# Tuliskan kode (tidak harus dalam bentuk fungsi) untuk melakukan training terhadap NN\n",
    "# expected_output: parameter Theta_1 dan Theta_2 yang telah ditraining/update sebanyak 100 kali iterasi\n",
    "# note: Theta_1 dan Theta_2 merupakan matrix\n",
    "# score: 4\n",
    "dataset = load_csv('exam_data.csv')\n",
    "\n",
    "X = str_feature_to_float(dataset)\n",
    "Y = str_target_to_integer(dataset)\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split (X, Y)\n",
    "Y_train = one_hot_encoding(Y_train)\n",
    "Y_test = one_hot_encoding(Y_test)\n",
    "\n",
    "Theta = initialize_network(X_train[0].size, 20, Y_train[0].size)\n",
    "Lambda = 0.8\n",
    "\n",
    "learning_rate = 0.01\n",
    "epoch = 100\n",
    "m = X_train.shape[0]\n",
    "big_delta = [[] for _ in range(len(Theta))]\n",
    "    \n",
    "# J_history = []\n",
    "# for i in range(len(Theta)):\n",
    "#     big_delta[i] = np.zeros(Theta[i].shape, dtype=np.float64)\n",
    "# for i in range (epoch):\n",
    "#     predicted = []\n",
    "#     for k in range(m):\n",
    "#         a = forward_propagation(Theta, X_train[k])\n",
    "#         predicted.append(a[-1].flatten())\n",
    "#         new_big_delta = back_propagation(Theta, big_delta, a, Y_train[k])\n",
    "#         big_delta = new_big_delta[:]\n",
    "#         new_theta = parameter_update(Theta, big_delta, m, Lambda, learning_rate)\n",
    "#         Theta = new_theta[:]\n",
    "#     J = cost_function(Theta, Y_train, np.array(predicted), Lambda)\n",
    "#     J_history.append(J)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8869047619047619"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_accuracy(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot cost function value untuk tiap iterasi/epoch pada step training dengan menggunakan matplotlib, \n",
    "# dan buat analisis singkat apakah model NN yang didevelop \n",
    "# sudah baik atau masih perlu modifikasi/improvement.\n",
    "# score: 6\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import pyplot\n",
    "\n",
    "def plotHistory(x, y, label_X, label_Y, radius):\n",
    "    fig = pyplot.figure()\n",
    "    pyplot.plot(x, y, 'ro', ms=radius, mec='k')\n",
    "    pyplot.xlabel(label_X)\n",
    "    pyplot.ylabel(label_Y)\n",
    "    pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXgAAAEGCAYAAABvtY4XAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAATF0lEQVR4nO3de5BkZ3nf8e+PlbhIIIQ9iwtL4BU2hQ0ESTDlAoSxLRFHYIJ8wYmcyEWmXN5KxRXA5ZoNFE6p8H9ZGcou38JG9lgOKuFYSAGTFAURt6KIJc8KAYIVBsRNIFszZVsSvgghnvzRZ0PvMD3bu9One/rt76eqa7pPn+n3eXdnfvvuc06fTlUhSWrPo2ZdgCSpHwa8JDXKgJekRhnwktQoA16SGnXGrAsYtrS0VAcOHJh1GZI0N44ePbpZVfu3e25PBfyBAwdYX1+fdRmSNDeSfGnUc7ZoJKlRBrwkNcqAl6RGGfCS1CgDXpIaZcBLUqMMeElqVBMBv7m5yTXXXMPm5uasS5GkPaOJgF9bW+PQoUOsra3NuhRJ2jP21DtZT9fKysoJXyVJjQT80tISq6ursy5DkvaUJlo0kqTvZMBLUqMMeElqlAEvSY0y4CWpUQa8JDXKgJekRvUa8El+JcmnktyZ5IYkj+1zPEnSt/UW8EnOA14DLFfVc4B9wJV9jSdJOlHfLZozgMclOQM4C/haz+NJkjq9BXxVfRX4DeDLwL3A/VX13q37JTmYZD3J+sbGRl/lSNLC6bNF8yTgCuAC4HuBs5NctXW/qjpSVctVtbx///6+ypGkhdNni+alwBeqaqOqHgZuAl7U43iSpCF9BvyXgRckOStJgMuAYz2OJ0ka0mcP/lbgRuB24JPdWEf6Gk+SdKJerwdfVVcDV/c5hiRpe76TVZIaZcBLUqMMeElqlAEvSY0y4CWpUQa8JDXKgJekRhnwktQoA16SGmXAS1KjDHhJapQBL0mNMuAlqVEGvCQ1yoCXpEYZ8JLUKANekhplwEtSowx4SWpUbwGf5JlJ7hi6PZDkdX2NJ0k6UW8ful1VnwEuAkiyD/gqcHNf40mSTjStFs1lwOer6ktTGk+SFt60Av5K4IbtnkhyMMl6kvWNjY0plSNJ7es94JM8Gngl8KfbPV9VR6pquaqW9+/f33c5krQwprGCfxlwe1X99RTGkiR1phHwP8+I9owkqT+9BnySs4B/DtzU5ziSpO/U22mSAFX1D8B39zmGJGl7vpNVkhplwEtSowx4SWqUAS9JjTLgJalRBrwkNcqAl6RGGfCS1CgDXpIaZcBLUqMMeElqlAEvSY0y4CWpUQa8JDXKgJekRhnwktQoA16SGmXAS1KjDHhJalTfH7p9bpIbk9yV5FiSF/Y5niTp23r90G3gt4D3VNWrkjwaOKvn8SRJnd4CPsk5wEuAfwdQVd8AvtHXeJKkE/XZonk6sAGsJflYkmuTnL11pyQHk6wnWd/Y2OixHElaLH0G/BnA84Dfr6qLgb8HXr91p6o6UlXLVbW8f//+HsuRpMXSZ8DfA9xTVbd2j29kEPiSpCnoLeCr6q+AryR5ZrfpMuDTfY0nSTpR32fR/Efg+u4MmruBlZ7HkyR1eg34qroDWO5zDEnS9nwnqyQ1yoCXpEYZ8JLUKANekhplwEtSo04a8En2TaMQSdJkjbOC/1ySa5I8q/dqJEkTM07APxf4S+DaJH/eXRzsnJ7rkiTt0kkDvqoerKr/VlUvAg4BVwP3JrkuyQ/0XqEk6bSM1YNP8sokNzP4AI83M7gU8J8B/7vn+iRJp2mcSxV8FvgAcE1VfXRo+41JXtJPWZKk3dox4LszaP6oqn59u+er6jW9VCVJ2rUdWzRV9Qjw41OqRZI0QeO0aD6a5HeAP2HwqUwAVNXtvVUlSdq1cQL+Rd3X4TZNAZdOvhxJ0qScNOCryhaNJM2hcU6TfGKStyRZ725vTvLEaRQnSTp947yT9Q+BB4F/1d0eANb6LEqStHvj9OC/v6p+dujxm5Lc0VdBkqTJGCfg/zHJi6vqIwBJLgH+cZwXT/JFBqv/R4BvVpWfzypJUzJOwP974I+H+u5/C7z6FMb48araPOXKJEm7Mk7AP1BVFx6/gmRVPZDkgp7rkiTt0jgHWd8Bg2Cvqge6bTeO+foFvDfJ0SQHT6dASdLpGbmCT/KDwLOBJyb5maGnzgEeO+brX1JVX0vyZOB9Se6qqg9vGecgcBDgaU972ikVL0kabacWzTOBVwDnAv9yaPuDwC+N8+JV9bXu633d5YZ/GPjwln2OAEcAlpeXa+zKJUk7GhnwVfVO4J1JXlhV//dUXzjJ2cCjqurB7v5PcOLlDiRJPRqnB//TSc5JcmaSW5JsJrlqjO/7HuAjST4O3Ab8r6p6z66qlSSNbZyzaH6iqg4l+WngHuDnGHwAyNt2+qaquhu4cPclSpJOxzgr+DO7ry8Hbqiqv+mxHknShIyzgv+zJHcxePfqf0iyH/infsuSJO3WSVfwVfV64IXAclU9zOBDP67ouzBJ0u7sdB78pVX1/uFz4JMM73JTn4VJknZnpxbNjwLv58Rz4I8rDHhJ2tN2Og/+6u7ryvTKkSRNykkPsiZ5DPCzwIHh/avKNy1J0h42zlk07wTuB44CD/VbjiRpUsYJ+POr6vLeK5EkTdQ4b3T6aJJ/1nslkqSJ2uk0yU8yOFvmDGAlyd0MWjQBqqqeO50SJUmnY6cWzSumVsUEbW5usra2xsrKCktLS7MuR5JmZqfTJL80zUImZW1tjUOHDgGwuro642okaXbGOcg6V1ZWVk74KkmLqrmAX1pacuUuSex8kPVBBgdZt/MQ8HngjVV1Sx+FSZJ2Z6ce/BNGPZdkH/Ac4PruqyRpjxnnPPjvUFWPVNXHgd+ecD2SpAk5rYA/rqreOqlCJEmTtauAlyTtXb0HfJJ9ST6W5N19jyVJ+rZprOBfCxybwjiSpCG9BnyS84GfBK7tcxxJ0nfqewX/m8Ah4FujdkhyMMl6kvWNjY2ey5GkxdFbwCd5BXBfVR3dab+qOlJVy1W1vH///r7KkaSF0+cK/hLglUm+CLwduDTJ23ocT5I0pLeAr6o3VNX5VXUAuBJ4f1Vd1dd4kqQTeR68JDVqKleTrKoPAh+cxliSpAFX8JLUKANekhplwEtSowx4SWqUAS9JjTLgJalRBrwkNcqAl6RGGfCS1CgDXpIaZcBLUqMMeEmaoc3NTa655ho2Nzcn/toGvCTN0NraGocOHWJtbW3irz2Vq0lKkra3srJywtdJcgUvSVM23JZZWlpidXWVpaWliY9jwEvSlPXZlhlmi0aSpmBzc5O1tTVWVlZ6bcsMM+AlaQqOr9oBVldXWV1d7X1MA16SpmBaq/ZhvfXgkzw2yW1JPp7kU0ne1NdYkrQXTetg6ih9HmR9CLi0qi4ELgIuT/KCHseTpD1lWgdTR+mtRVNVBXy9e3hmd6u+xpOkvWAWB1NH6fU0yST7ktwB3Ae8r6pu3Wafg0nWk6xvbGz0WY4k9W541T6LtsywXg+yVtUjwEVJzgVuTvKcqrpzyz5HgCMAy8vLrvAlzZ29tGofNpWzaKrq75J8ELgcuPMku0vSXJnFKZDj6C3gk+wHHu7C/XHAS4H/0td4kjRNe3XVPqzPFfxTgOuS7GPQ6/8fVfXuHseTpKnZq6v2YX2eRfMJ4OK+Xl+Spm0eVu3DfCerJI1pHlbtwwx4SdrBvK3ahxnwkrSDeVu1DzPgJWnI8Ip9aWlp7lbtw/zAD0kasvX6MbN+N+puuIKXtPDmuc++EwNe0sKb5z77Tgx4SQup1VX7MHvwkhbG8Adw7KWrPvbFFbykhTHciml11T7MgJfUtFGtmOOr9pYZ8JKa1uoB1HEY8JKaswgHUMfhQVZJTVi0A6jjcAUvqQmLdgB1HAa8pLm1yAdQx2GLRtJcsRUzPlfwkuaKrZjxGfCS9jxbMaentxZNkqcm+UCSY0k+leS1fY0lqT22YnavzxX8N4FfrarbkzwBOJrkfVX16R7HPMHWC/dLmh+2Ynavt4CvqnuBe7v7DyY5BpwHTC3gt76DTdLeZitmsqZyFk2SA8DFwK3bPHcwyXqS9Y2NjYmOu7KywuHDh3f8V3/4v4HD9yVNh62YHlVVrzfg8cBR4GdOtu/zn//86svGxkYdPny4NjY2Trh/+PDhAurw4cMn3B+1//D9nV53L9wftz5p2kb9DvpzeeqA9RqRqb2eRZPkTOAdwPVVdVOfY53McLsG2LG3t7KyMnL/4furq6tj7Ter++PWd3y+x/8MtrvvKkq7sfV42Kj+uq2Yyeot4JME+APgWFW9pa9xxjUqyLf+QB2/P2r/Ua93sv1mdX+c+nbzj4DBr1GGQ33r8TBDfUpGLe13ewNeDBTwCeCO7vbynb6nzxaNRhunjXOqrSwtJlsv08cOLZree/CncjPg967dBL/aZqjPlgGv3owT/P6it8e/673DgNfUGQDt8e90b9op4L0WjXoxfOBs+IDa1rMnPFi7t406UOpB0jkxKvlncXMF375Rq8Ctz2l2XKnPF2zRaC/aGhiGyXR5/KQNOwW8LRrNzNb/2tvK6d+olgts/+Y/2y/zzYDXnmHffnKGgxw4aR/9OEO9MaOW9rO42aLRdsZpHyx6K2Gndpctl7ZhD16tmOSF4vaCSV1YbqcD1ntx3pqcnQLeFo3myqg2znG7vbbOqPtLS0sj2x67uT+pi9Vt/bMYdY0lLRYDXnNrNxeKO9Vg7evKoZO6WJ19c21r1NJ+FjdbNJqWvq6tfzqvK+0GO7RoMnh+b1heXq719fVZlyFJcyPJ0apa3u65qXxknyRp+gx4SWqUAS9JjTLgJalRBrwkNcqAl6RGGfCS1Kg9dR58kg3gS6fwLUvAZk/l7FWLOGdYzHkv4pxhMee9mzl/X1Xt3+6JPRXwpyrJ+qgT/Fu1iHOGxZz3Is4ZFnPefc3ZFo0kNcqAl6RGzXvAH5l1ATOwiHOGxZz3Is4ZFnPevcx5rnvwkqTR5n0FL0kawYCXpEbNZcAnuTzJZ5J8LsnrZ11PX5I8NckHkhxL8qkkr+22f1eS9yX5bPf1SbOuddKS7EvysSTv7h4vwpzPTXJjkru6v/MXtj7vJL/S/WzfmeSGJI9tcc5J/jDJfUnuHNo2cp5J3tDl22eS/IvTHXfuAj7JPuB3gZcBzwJ+PsmzZltVb74J/GpV/RDwAuCXu7m+Hrilqp4B3NI9bs1rgWNDjxdhzr8FvKeqfhC4kMH8m513kvOA1wDLVfUcYB9wJW3O+Y+Ay7ds23ae3e/4lcCzu+/5vS73TtncBTzww8DnquruqvoG8HbgihnX1Iuqureqbu/uP8jgF/48BvO9rtvtOuCnZlNhP5KcD/wkcO3Q5tbnfA7wEuAPAKrqG1X1dzQ+bwafC/24JGcAZwFfo8E5V9WHgb/ZsnnUPK8A3l5VD1XVF4DPMci9UzaPAX8e8JWhx/d025qW5ABwMXAr8D1VdS8M/hEAnjy7ynrxm8Ah4FtD21qf89OBDWCta01dm+RsGp53VX0V+A3gy8C9wP1V9V4anvMWo+Y5sYybx4DPNtuaPtczyeOBdwCvq6oHZl1Pn5K8Arivqo7OupYpOwN4HvD7VXUx8Pe00ZoYqes5XwFcAHwvcHaSq2Zb1Z4wsYybx4C/B3jq0OPzGfy3rklJzmQQ7tdX1U3d5r9O8pTu+acA982qvh5cArwyyRcZtN8uTfI22p4zDH6u76mqW7vHNzII/Jbn/VLgC1W1UVUPAzcBL6LtOQ8bNc+JZdw8BvxfAM9IckGSRzM4GPGuGdfUiyRh0JM9VlVvGXrqXcCru/uvBt457dr6UlVvqKrzq+oAg7/b91fVVTQ8Z4Cq+ivgK0me2W26DPg0bc/7y8ALkpzV/axfxuA4U8tzHjZqnu8CrkzymCQXAM8AbjutEapq7m7Ay4G/BD4PvHHW9fQ4zxcz+K/ZJ4A7utvLge9mcNT9s93X75p1rT3N/8eAd3f3m58zcBGw3v19/0/gSa3PG3gTcBdwJ/Dfgce0OGfgBgbHGR5msEL/xZ3mCbyxy7fPAC873XG9VIEkNWoeWzSSpDEY8JLUKANekhplwEtSowx4SWqUAS9NQJIfO37lS2mvMOAlqVEGvBZKkquS3JbkjiRv7a47//Ukb05ye5Jbkuzv9r0oyZ8n+USSm49frzvJDyT5P0k+3n3P93cv//ih67lf3707U5oZA14LI8kPAf8auKSqLgIeAf4tcDZwe1U9D/gQcHX3LX8M/Keqei7wyaHt1wO/W1UXMrh2yr3d9ouB1zH4nIKnM7iujjQzZ8y6AGmKLgOeD/xFt7h+HIMLPH0L+JNun7cBNyV5InBuVX2o234d8KdJngCcV1U3A1TVPwF0r3dbVd3TPb4DOAB8pP9pSdsz4LVIAlxXVW84YWPyn7fst9P1O3Zquzw0dP8R/P3SjNmi0SK5BXhVkifD//9MzO9j8Hvwqm6ffwN8pKruB/42yY90238B+FANrsd/T5Kf6l7jMUnOmuospDG5wtDCqKpPJ/k14L1JHsXgyn6/zODDNZ6d5ChwP4M+PQwu4fpfuwC/G1jptv8C8NYkv969xs9NcRrS2LyapBZekq9X1eNnXYc0abZoJKlRruAlqVGu4CWpUQa8JDXKgJekRhnwktQoA16SGvX/ALIBFTSQFzUHAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "it = [i+1 for i in range(epoch)]\n",
    "plotHistory(it, J_history, 'epoch', 'J history', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
